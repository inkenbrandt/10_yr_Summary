{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-18T13:29:13.642367Z",
     "start_time": "2018-01-18T13:29:11.739904Z"
    }
   },
   "outputs": [],
   "source": [
    "#import urllib2\n",
    "import xmltodict\n",
    "import pandas as pd\n",
    "import datetime \n",
    "#from httplib import BadStatusLine\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "import wellapplication as wa\n",
    "import glob\n",
    "import os\n",
    "from shutil import copyfile\n",
    "import loggerloader as ll\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1050\t1044541\tBig Springs Ranch\n",
    "1050\t1044541\n",
    "1050\t101044541\tBig Springs Ranch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T23:37:56.066639Z",
     "start_time": "2018-01-17T23:35:53.277396Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "baronames = ['1038964','1044788','1044779','pw03baro','pw19baro',\n",
    "             '1034820','pw10baro','1028270',\n",
    "            'pw03 baro','pw19 baro','pw10 baro']\n",
    "dir = \"G:/My Drive/WORK/Snake Valley/Transducer Data/\"\n",
    "for pack in os.walk(dir):\n",
    "    #print(pack[0])\n",
    "    for baroname in baronames:\n",
    "        for i in glob.glob(pack[0]+'/'+'*{:}*'.format(baroname)):\n",
    "            if i[-4:] in ['.lev','.xle']:\n",
    "                dater = str(datetime.datetime.fromtimestamp(os.path.getmtime(i)).strftime('%Y-%m-%d'))\n",
    "                rightfile = dater + \"_\" + os.path.basename(i)\n",
    "                print(dater+\"_\"+os.path.basename(i))\n",
    "                baro = \"G:/My Drive/WORK/Snake Valley/Barometers1/\"\n",
    "                try:\n",
    "                    copyfile(i, os.path.join(baro, rightfile))\n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T23:03:37.124277Z",
     "start_time": "2018-01-17T23:03:19.569040Z"
    }
   },
   "outputs": [],
   "source": [
    "baronames = ['1044541','_1050_','Big Springs Ranch']\n",
    "dir = \"G:/My Drive/WORK/Snake Valley/Transducer Data/\"\n",
    "for pack in os.walk(dir):\n",
    "    #print(pack[0])\n",
    "    for baroname in baronames:\n",
    "        for i in glob.glob(pack[0]+'/'+'*{:}*'.format(baroname)):\n",
    "            if i[-4:] in ['.lev','.xle']:\n",
    "                dater = str(datetime.datetime.fromtimestamp(os.path.getmtime(i)).strftime('%Y-%m-%d'))\n",
    "                rightfile = dater + \"_\" + os.path.basename(i)\n",
    "                print(dater+\"_\"+os.path.basename(i))\n",
    "                baro = \"G:/My Drive/WORK/Snake Valley/P1050/\"\n",
    "                try:\n",
    "                    copyfile(i, os.path.join(baro, rightfile))\n",
    "                except:\n",
    "                    pass\n",
    "    #file_extension.append(os.path.splitext(file)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T23:04:24.937817Z",
     "start_time": "2018-01-17T23:04:24.917755Z"
    }
   },
   "outputs": [],
   "source": [
    "manual_file = 'G:/My Drive/WORK/Snake Valley/manual_measurements.csv'\n",
    "manual = pd.read_csv(manual_file, index_col=\"DateTime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T23:04:29.070479Z",
     "start_time": "2018-01-17T23:04:28.023115Z"
    }
   },
   "outputs": [],
   "source": [
    "saved_csvs = ['pw03','1044788','1044779','pw19','pw10']\n",
    "\n",
    "barometerids = {'pw03':9003,'1044788':9024,'1044779':9025,'pw10':9027,'pw19':9049,'sg25':9061}\n",
    "barodict = {\"PW10 Barometer\":9027, \"PW19 Barometer\":9049, \"SG25 Barometer\":9061, \n",
    "            \"Leland-Harris Barometer\":9025, \"Twin Springs Barometer\":9024, \"PW03 Barometer\":9003}\n",
    "bpdict = {'pw03':'9003','pw10':'9027','pw19':'9049','twin':'9024','leland':'9025'}       \n",
    "\n",
    "baro_data = {}\n",
    "\n",
    "barodrive = 'G:/My Drive/WORK/Snake Valley/Barometers/'\n",
    "\n",
    "head = ['MEASUREDLEVEL', 'TEMP', 'LOCATIONID']\n",
    "ind_head = ['READINGDATE']\n",
    "for csv in saved_csvs:\n",
    "    baro_data[csv] = pd.read_csv(barodrive + '{:}.csv'.format(csv),\n",
    "                                index_col=0,parse_dates=True)\n",
    "    baro_data[csv].sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T23:04:33.580624Z",
     "start_time": "2018-01-17T23:04:33.558063Z"
    }
   },
   "outputs": [],
   "source": [
    "def new_trans_imp(infile):\n",
    "    \"\"\"This function uses an imports and cleans the ends of transducer file.\n",
    "\n",
    "    Args:\n",
    "        infile (file):\n",
    "            complete file path to input file\n",
    "        xle (bool):\n",
    "            if true, then the file type should be xle; else it should be csv\n",
    "\n",
    "    Returns:\n",
    "        A Pandas DataFrame containing the transducer data\n",
    "    \"\"\"\n",
    "    file_ext = os.path.splitext(infile)[1]\n",
    "    if file_ext == '.xle':\n",
    "        well = ll.new_xle_imp(infile)\n",
    "    elif file_ext == '.lev':\n",
    "        # open text file\n",
    "        with open(infile) as fd:\n",
    "            # find beginning of data\n",
    "            indices = fd.readlines().index('[Data]\\n')\n",
    "\n",
    "        # convert data to pandas dataframe starting at the indexed data line\n",
    "        well = pd.read_table(infile, parse_dates=True, sep='     ', index_col=0,\n",
    "                          skiprows=indices + 2, names=['DateTime', 'Level', 'Temperature'], skipfooter=1,\n",
    "                          engine='python')\n",
    "        # add extension-free file name to dataframe\n",
    "        well['name'] = ll.getfilename(infile)\n",
    "    elif file_ext == '.csv':\n",
    "        well = ll.new_csv_imp(infile)\n",
    "    else:\n",
    "        print('filetype not recognized')\n",
    "        pass\n",
    "    return ll.dataendclean(well, 'Level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T23:04:45.532425Z",
     "start_time": "2018-01-17T23:04:35.315920Z"
    }
   },
   "outputs": [],
   "source": [
    "import arcpy\n",
    "conn_file_root = \"C:/Users/PAULINKENBRANDT/AppData/Roaming/ESRI/Desktop10.5/ArcCatalog/\"\n",
    "conn_file = \"UGS_SDE.sde\" #production\n",
    "arcpy.env.workspace = conn_file_root + conn_file\n",
    "gw_reading_table = \"UGGP.UGGPADMIN.UGS_GW_reading\"\n",
    "stations_table =  \"UGGP.UGGPADMIN.UGS_NGWMN_Monitoring_Locations\"\n",
    "well_table = ll.table_to_pandas_dataframe(stations_table)\n",
    "\n",
    "well_table.set_index('AltLocationID',inplace=True)\n",
    "well_table = ll.table_to_pandas_dataframe(stations_table)\n",
    "well_table.set_index('AltLocationID',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T23:06:02.786069Z",
     "start_time": "2018-01-17T23:06:00.127998Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "beff,rawwell = {},{}\n",
    "j=0\n",
    "for file in glob.glob(\"G:/My Drive/WORK/Snake Valley/P1050/*\"):\n",
    "    print(file)\n",
    "    try:\n",
    "        rawwell[j] = new_trans_imp(file)\n",
    "        j+=1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "rawdf = pd.concat(rawwell)\n",
    "rawdf.reset_index(inplace=True)\n",
    "rawdf.set_index(['DateTime'],inplace=True)\n",
    "rawdf.sort_index(inplace=True)\n",
    "rawdf.drop_duplicates(inplace=True)\n",
    "rawdf = rawdf[rawdf.index < pd.datetime(2014,11,1)]\n",
    "rawdf.Level.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T23:06:48.947840Z",
     "start_time": "2018-01-17T23:06:48.844052Z"
    }
   },
   "outputs": [],
   "source": [
    "rawdf.drop(['level_0','name'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T23:09:10.830908Z",
     "start_time": "2018-01-17T23:09:10.816370Z"
    }
   },
   "outputs": [],
   "source": [
    "rawdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T23:23:46.359147Z",
     "start_time": "2018-01-17T23:23:46.335079Z"
    }
   },
   "outputs": [],
   "source": [
    "baro_data['pw03'][baro_data['pw03'].index > pd.datetime(2011,6,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T22:29:00.851113Z",
     "start_time": "2018-01-17T22:15:32.332378Z"
    }
   },
   "outputs": [],
   "source": [
    "corrwl = ll.well_baro_merge(rawdf, baro_data['pw03'], barocolumn='Level', vented=False, sampint=600)\n",
    "corrwl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T22:47:31.252588Z",
     "start_time": "2018-01-17T22:47:30.976883Z"
    }
   },
   "outputs": [],
   "source": [
    "wellid='1050'\n",
    "#wls, be = correct_be(wellid, well_table, corrwl,be=0.72)\n",
    "stdata = well_table.loc[wellid,:]\n",
    "man_sub = manual[manual['Location ID'] == int(wellid)]\n",
    "well_elev = float(stdata['Altitude'])    \n",
    "stickup = float(stdata['Offset'])\n",
    "man_sub.loc[:, 'MeasuredDTW'] = man_sub['Water Level (ft)'] * -1\n",
    "man_sub.loc[:, 'Meas_GW_Elev'] = man_sub['MeasuredDTW'].apply(lambda x: float(well_elev) + (x + float(stickup)),\n",
    "                                                                  1)\n",
    "print('Stickup: {:}, Well Elev: {:}'.format(stickup, well_elev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T22:49:28.881229Z",
     "start_time": "2018-01-17T22:49:28.874713Z"
    }
   },
   "outputs": [],
   "source": [
    "corrwl.drop(['level_0'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T22:54:04.455035Z",
     "start_time": "2018-01-17T22:53:57.955090Z"
    }
   },
   "outputs": [],
   "source": [
    "# fix transducer drift\n",
    "wls = corrwl\n",
    "dft = ll.fix_drift(wls, man_sub, meas='corrwl', manmeas='MeasuredDTW')\n",
    "drift = np.round(float(dft[1]['drift'].values[0]), 3)\n",
    "\n",
    "df = dft[0]\n",
    "df.sort_index(inplace=True)\n",
    "first_index = df.first_valid_index()\n",
    "rowlist, fieldnames = ll.prepare_fieldnames(df, wellid, stickup, well_elev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-17T22:54:20.979314Z",
     "start_time": "2018-01-17T22:54:20.702580Z"
    }
   },
   "outputs": [],
   "source": [
    "dfrow = rowlist.set_index('READINGDATE')\n",
    "dfrow['WATERELEVATION'].plot()\n",
    "plt.scatter(man_sub.index, man_sub['Meas_GW_Elev'],color='Red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=0\n",
    "welly = {}\n",
    "\n",
    "welliddict = {'7002':'D3-41','7001':'F3-06'} \n",
    "wellids = ['7002','7001']\n",
    "beff,wells = {},{}\n",
    "for wellid in wellids:\n",
    "    for file in glob.glob(\"G:/My Drive/WORK/Juab/WellData/*{:}}*\".format(welliddict[wellid])):\n",
    "        print(file)\n",
    "        well = ll.new_trans_imp(file)\n",
    "        corrwl = ll.well_baro_merge(well, baro_out['9062'], barocolumn='MEASUREDLEVEL', vented=False)\n",
    "\n",
    "        wls, be = correct_be(wellid, well_table, corrwl,be=0.72)\n",
    "        stdata = well_table.loc[wellid,:]\n",
    "        man_sub = manual[manual['Location ID'] == int(wellid)]\n",
    "        well_elev = float(stdata['Altitude'])    \n",
    "        stickup = float(stdata['Offset'])\n",
    "        man_sub.loc[:, 'MeasuredDTW'] = man_sub['Water Level (ft)'] * -1\n",
    "        man_sub.loc[:, 'Meas_GW_Elev'] = man_sub['MeasuredDTW'].apply(lambda x: float(well_elev) + (x + float(stickup)),\n",
    "                                                                          1)\n",
    "        print('Stickup: {:}, Well Elev: {:}'.format(stickup, well_elev))\n",
    "\n",
    "        # fix transducer drift\n",
    "\n",
    "        dft = ll.fix_drift(wls, man_sub, meas='BAROEFFICIENCYLEVEL', manmeas='MeasuredDTW')\n",
    "        drift = np.round(float(dft[1]['drift'].values[0]), 3)\n",
    "\n",
    "        df = dft[0]\n",
    "        df.sort_index(inplace=True)\n",
    "        first_index = df.first_valid_index()\n",
    "        rowlist, fieldnames = ll.prepare_fieldnames(df, wellid, stickup, well_elev)\n",
    "        #beff[j] = m\n",
    "        wells[j] = rowlist \n",
    "        j += 1\n",
    "    welly[wellid] = pd.concat(wells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive = 'E:'\n",
    "raw_archive_folder = drive + '/PROJECTS/Snake Valley Water/Transducer Data/Raw_data_archive'\n",
    "folder = raw_archive_folder + '/2016/2016 q2/'\n",
    "enteredFolder = folder + '/entered/'\n",
    "checkFolder = folder + '/toCheck/'\n",
    "wellinfofile = drive + raw_archive_folder + '/well table 2015-03-23.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputfile = \"E:/PROJECTS/Snake Valley Water/Transducer Data/Raw_data_archive/2016/2016 q2/ag13c 2016-08-02.xle\"\n",
    "manualwls = raw_archive_folder + '/All tape measurements.csv'\n",
    "manual = pd.read_csv(manualwls, index_col=\"DateTime\", engine=\"python\")\n",
    "barofile = raw_archive_folder + '/baro.csv'\n",
    "baro = pd.read_csv(barofile,index_col=0, parse_dates=True)\n",
    "wellinfo = pd.read_csv(folder + '/wellinfo4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g, drift, wellname = wa.imp_new_well(inputfile, wellinfo, manual, baro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wa.new_xle_imp(inputfile)\n",
    "    \n",
    "jf = wa.jumpfix(df, 'Level', threashold=0.005)\n",
    "jf['newVal'][-1] > 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xle = inputfile\n",
    "xle_df = wa.new_xle_imp(xle)\n",
    "manual35 = manual[manual['WellID']==35]\n",
    "manual35['dt'] = pd.to_datetime(manual35.index)\n",
    "manual_35 = manual35.reset_index()\n",
    "manual_35.set_index('dt',inplace=True)\n",
    "\n",
    "fd = wa.fix_drift(xle_df, manual_35, meas='Level', manmeas='MeasuredDTW', outcolname='DriftCorrection')\n",
    "'DriftCorrection' in list(fd[0].columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fix_drift(xle_df, manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well = wa.new_xle_imp(inputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baro['Level'] = baro['pw03']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wellbaro = wa.well_baro_merge(well, baro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wellbaro[['corrwl','Level']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_drift(well, manualfile, meas= 'Level', manmeas =  'MeasuredDTW', outcolname = 'DriftCorrection'): \n",
    "    \"\"\"Remove transducer drift from nonvented transducer data.\n",
    "    Args:\n",
    "        well (pandas.core.frame.DataFrame):\n",
    "            Pandas DataFrame of merged water level and barometric data; index must be datetime\n",
    "        manualfile (pandas.core.frame.DataFrame):\n",
    "            Pandas DataFrame of manual measurements\n",
    "        meas (str):\n",
    "            name of column in well DataFrame containing transducer data to be corrected\n",
    "        manmeas (str):\n",
    "            name of column in manualfile Dataframe containing manual measurement data\n",
    "        outcolname (str):\n",
    "            name of column resulting from correction\n",
    "    Returns:\n",
    "        wellbarofixed (pandas.core.frame.DataFrame):\n",
    "            corrected water levels with bp removed\n",
    "        driftinfo (pandas.core.frame.DataFrame):\n",
    "            dataframe of correction parameters\n",
    "    \"\"\"\n",
    "    #breakpoints = self.get_breakpoints(wellbaro, manualfile)\n",
    "    breakpoints = []\n",
    "    \n",
    "    for i in range(len(manualfile)):\n",
    "        breakpoints.append(wa.fcl(wellbaro, pd.to_datetime(manualfile.index)[i]).name)\n",
    "    breakpoints = sorted(list(set(breakpoints)))\n",
    "\n",
    "    bracketedwls, drift_features = {},{}\n",
    "    dtnm = wellbaro.index.name\n",
    "    manualfile['julian'] = manualfile.index.to_julian_date()\n",
    "    \n",
    "    for i in range(len(breakpoints) - 1):\n",
    "        # Break up pandas dataframe time series into pieces based on timing of manual measurements\n",
    "        bracketedwls[i] = wellbaro.loc[(wellbaro.index.to_datetime() > breakpoints[i]) & (wellbaro.index.to_datetime() < breakpoints[i + 1])]\n",
    "\n",
    "        if len(bracketedwls[i]) > 0:\n",
    "            bracketedwls[i].loc[:, 'julian'] = bracketedwls[i].index.to_julian_date()\n",
    "            \n",
    "            last_trans = bracketedwls[i].ix[-1, meas] # last transducer measurment\n",
    "            first_trans = bracketedwls[i].ix[0, meas] # first transducer measurement\n",
    "            \n",
    "            last_man = wa.fcl(manualfile, breakpoints[i + 1]) # first manual measurment\n",
    "            first_man = wa.fcl(manualfile, breakpoints[i]) # last manual mesurement\n",
    "            \n",
    "            # intercept of line = value of first manual measurement\n",
    "            b = first_man[manmeas] - first_trans\n",
    "            # slope of line = change in difference between manual and transducer over time\n",
    "            m = ((last_man[manmeas] - last_trans) - (first_man[manmeas]-first_trans)) / (last_man['julian'] - first_man['julian'])\n",
    "            # datechange = amount of time between manual measurements\n",
    "            bracketedwls[i].loc[:, 'datechange'] = bracketedwls[i].ix[:, 'julian'] - bracketedwls[i].ix[0, 'julian']\n",
    "            \n",
    "            #bracketedwls[i].loc[:, 'wldiff'] = bracketedwls[i].loc[:, meas] - first_trans\n",
    "            bracketedwls[i].loc[:, outcolname] = bracketedwls[i][['datechange', meas]].apply(lambda x: x[1] + (m * x[0] + b), 1)\n",
    "            drift_features[i] = {'begining':first_man, 'end':last_man, 'intercept':b, 'slope':m,\n",
    "                                'first_meas':first_man[manmeas],'last_meas':last_man[manmeas]}\n",
    "        else:\n",
    "            pass\n",
    "    wellbarofixed = pd.concat(bracketedwls)\n",
    "    wellbarofixed.reset_index(inplace=True)\n",
    "    wellbarofixed.set_index(dtnm, inplace=True)\n",
    "    drift_info = pd.DataFrame(drift_features)\n",
    "    return wellbarofixed, drift_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual35 = manual[manual['WellID']==35]\n",
    "manual35['dt'] = pd.to_datetime(manual35.index)\n",
    "manual_35 = manual35.reset_index()\n",
    "manual_35.set_index('dt',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed= fix_drift_slope(wellbaro, manual_35, 'Level')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fixed.index\n",
    "y = fixed['DriftCorrection']\n",
    "\n",
    "x1 = manual_35.index\n",
    "y1 = manual_35['MeasuredDTW']\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.scatter(x1,y1)\n",
    "plt.xlim('5/1/2016','8/15/2016')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wellbaro['dbp'] = wellbaro.barometer.diff()\n",
    "wellbaro['dwl'] = wellbaro.Level.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wellbaro['dbp'] = wellbaro.barometer.diff()\n",
    "wellbaro['dwl'] = wellbaro.Level.diff()\n",
    "wellbaro['corrwl'] = wellbaro[['dbp','dwl']].apply(lambda x: x[1]-x[0],1).cumsum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wellbaro['corrwl'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def well_baro_merge(wellfile, barofile, sampint=60):\n",
    "    \"\"\"Remove barometric pressure from nonvented transducers.\n",
    "    Args:\n",
    "        wellfile (pandas.core.frame.DataFrame):\n",
    "            Pandas DataFrame of water level data labeled 'Level'; index must be datetime\n",
    "        barofile (pandas.core.frame.DataFrame):\n",
    "            Pandas DataFrame barometric data labeled 'Level'; index must be datetime\n",
    "        sampint (int):\n",
    "            sampling interval in minutes; default 60\n",
    "\n",
    "    Returns:\n",
    "        wellbaro (Pandas DataFrame):\n",
    "           corrected water levels with bp removed\n",
    "    \"\"\"\n",
    "\n",
    "    # resample data to make sample interval consistent\n",
    "    baro = wa.hourly_resample(barofile, 0, sampint)\n",
    "    well = wa.hourly_resample(wellfile, 0, sampint)\n",
    "\n",
    "    # reassign `Level` to reduce ambiguity\n",
    "    if 'Level' in list(baro.columns):\n",
    "        baro= baro.rename(columns = {'Level':'barometer'})\n",
    "    # combine baro and well data for easy calculations, graphing, and manipulation\n",
    "    wellbaro = pd.merge(well, baro, left_index=True, right_index=True, how='inner')\n",
    "    \n",
    "    wellbaro['dbp'] = wellbaro.barometer.diff()\n",
    "    wellbaro['dwl'] = wellbaro.Level.diff()\n",
    "    first_well = wellbaro.Level[0]\n",
    "\n",
    "    wellbaro['corrwl'] = wellbaro[['dbp','dwl']].apply(lambda x: x[1]-x[0],1).cumsum()+first_well\n",
    "    \n",
    "    return wellbaro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baro_drift_correct(wellfile, barofile, manualfile, sampint=60, wellelev=4800, stickup=0):\n",
    "    \"\"\"Remove barometric pressure and corrects drift.\n",
    "    Args:\n",
    "        wellfile (pandas.core.frame.DataFrame):\n",
    "            Pandas DataFrame of water level data labeled 'Level'; index must be datetime\n",
    "        barofile (pandas.core.frame.DataFrame):\n",
    "            Pandas DataFrame barometric data labeled 'Level'; index must be datetime\n",
    "        manualfile (pandas.core.frame.DataFrame):\n",
    "            Pandas DataFrame manual level data in the first column after the index; index must be datetime\n",
    "        sampint (int):\n",
    "            sampling interval in minutes; default 60\n",
    "        wellelev (int):\n",
    "            site ground surface elevation in feet\n",
    "        stickup (float):\n",
    "            offset of measure point from ground in feet\n",
    "\n",
    "    Returns:\n",
    "        wellbarofinal (Pandas DataFrame):\n",
    "           corrected water levels\n",
    "    \"\"\"\n",
    "    # Remove dangling ends\n",
    "    baroclean = dataendclean(barofile, 'Level')\n",
    "    wellclean = dataendclean(wellfile, 'Level')\n",
    "\n",
    "    # resample data to make sample interval consistent\n",
    "    baro = hourly_resample(baroclean, 0, sampint)\n",
    "    well = hourly_resample(wellclean, 0, sampint)\n",
    "\n",
    "    # reassign `Level` to reduce ambiguity\n",
    "    well['abs_feet_above_levelogger'] = well['Level']\n",
    "    baro['abs_feet_above_barologger'] = baro['Level']\n",
    "\n",
    "    # combine baro and well data for easy calculations, graphing, and manipulation\n",
    "    wellbaro = pd.merge(well, baro, left_index=True, right_index=True, how='inner')\n",
    "\n",
    "    # subtract barometric pressure from total pressure measured by transducer\n",
    "    wellbaro['adjusted_levelogger'] = wellbaro['abs_feet_above_levelogger'] - wellbaro['abs_feet_above_barologger']\n",
    "\n",
    "    breakpoints = []\n",
    "    for i in range(len(manualfile) + 1):\n",
    "        breakpoints.append(fcl(wellbaro, manualfile.index.to_datetime()[i - 1]).name)\n",
    "\n",
    "    last_man_wl, first_man_wl, last_tran_wl, driftlen = [], [], [], []\n",
    "    bracketedwls = {}\n",
    "    for i in range(len(manualfile) - 1):\n",
    "        # Break up time series into pieces based on timing of manual measurements\n",
    "        bracketedwls[i + 1] = wellbaro.loc[(wellbaro.index.to_datetime() > breakpoints[i + 1]) & (wellbaro.index.to_datetime() < breakpoints[i + 2])]\n",
    "        # get difference in transducer water measurements\n",
    "        bracketedwls[i + 1]['diff_wls'] = bracketedwls[i + 1]['abs_feet_above_levelogger'].diff()\n",
    "        # get difference of each depth to water from initial measurement\n",
    "        bracketedwls[i + 1].loc[:, 'DeltaLevel'] = bracketedwls[i + 1].loc[:, 'adjusted_levelogger'] - \\\n",
    "                                                   bracketedwls[i + 1].ix[0, 'adjusted_levelogger']\n",
    "        bracketedwls[i + 1].loc[:, 'MeasuredDTW'] = fcl(manualfile, breakpoints[i + 1])[0] - \\\n",
    "                                                    bracketedwls[i + 1].loc[:,'DeltaLevel']\n",
    "        last_man_wl.append(fcl(manualfile, breakpoints[i + 2])[0])\n",
    "        first_man_wl.append(fcl(manualfile, breakpoints[i + 1])[0])\n",
    "        last_tran_wl.append(\n",
    "            float(bracketedwls[i + 1].loc[max(bracketedwls[i + 1].index.to_datetime()), 'MeasuredDTW']))\n",
    "        driftlen.append(len(bracketedwls[i + 1].index))\n",
    "        bracketedwls[i + 1].loc[:, 'last_diff_int'] = np.round((last_tran_wl[i] - last_man_wl[i]), 4) / np.round(\n",
    "            driftlen[i] - 1.0, 4)\n",
    "        bracketedwls[i + 1].loc[:, 'DriftCorrection'] = np.round(\n",
    "            bracketedwls[i + 1].loc[:, 'last_diff_int'].cumsum() - bracketedwls[i + 1].loc[:, 'last_diff_int'], 4)\n",
    "\n",
    "    wellbarofixed = pd.concat(bracketedwls)\n",
    "    wellbarofixed.reset_index(inplace=True)\n",
    "    wellbarofixed.set_index('DateTime', inplace=True)\n",
    "    # Get Depth to water below casing\n",
    "    wellbarofixed.loc[:, 'DTWBelowCasing'] = wellbarofixed['MeasuredDTW'] - wellbarofixed['DriftCorrection']\n",
    "\n",
    "    # subtract casing height from depth to water below casing\n",
    "    wellbarofixed.loc[:, 'DTWBelowGroundSurface'] = wellbarofixed.loc[:,\n",
    "                                                    'DTWBelowCasing'] - stickup  # well riser height\n",
    "\n",
    "    # subtract depth to water below ground surface from well surface elevation\n",
    "    wellbarofixed.loc[:, 'WaterElevation'] = wellelev - wellbarofixed.loc[:, 'DTWBelowGroundSurface']\n",
    "\n",
    "    wellbarofinal = smoother(wellbarofixed, 'WaterElevation')\n",
    "\n",
    "    return wellbarofinal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
