{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import xmltodict\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as dates\n",
    "import matplotlib.ticker as tick\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import snake\n",
    "\n",
    "from datetime import datetime\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Drive = 'U'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `g[wellinfo[wellinfo['Well']==wellname]['closest_baro']]` instead if you want to match the closest barometer to the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "folder = Drive + ':\\\\GWP\\\\Groundwater\\\\Courthouse_Wash_Transducer_Data'\n",
    "wellinfofile = Drive + ':\\\\GWP\\\\Groundwater\\\\Courthouse_Wash_Transducer_Data\\\\wellinfo.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wellinfo = pd.read_csv(wellinfofile,header=0,index_col=0)\n",
    "wellinfo[\"G_Elev_m\"] = wellinfo[\"GroundElevation\"]/3.2808\n",
    "wellinfo[\"Well\"] = wellinfo['Well'].apply(lambda x: str(x).lower().strip())\n",
    "wellinfo['WellID'] = wellinfo.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wellinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Water Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "manualwls = Drive + ':\\\\GWP\\\\Groundwater\\\\Courthouse_Wash_Transducer_Data\\\\manual_measurements.csv'\n",
    "manual = pd.read_csv(manualwls, skiprows=0, parse_dates=1, index_col=\"DateTime\", engine=\"python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barometric Pressure Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compilation of Barometric Pressure Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "barofile = folder + '\\\\*baro*'\n",
    "barodata = snake.compilation(barofile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "barodata['Level']\n",
    "barodata.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "barodata = snake.hourly_resample(barodata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "infile = Drive + \":\\\\GWP\\\\Groundwater\\\\Courthouse_Wash_Transducer_Data\\\\\"\n",
    "pathlist = os.path.splitext(infile)[0].split('\\\\')\n",
    "barodata.to_csv(pathlist[0] + '\\\\' + pathlist[1] + '\\\\' + pathlist[2] + '\\\\' + pathlist[3] + '\\\\' + pathlist[4] + '\\\\' + 'baro' + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "barodata[['Level']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folder = Drive + \":\\\\GWP\\\\Groundwater\\\\Courthouse_Wash_Transducer_Data\"\n",
    "wellinfo = snake.make_files_table(folder, wellinfo)\n",
    "wellinfo.tail(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Water Level Tranducer Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export and Plot Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export Manual Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "manual.reset_index(inplace=True)\n",
    "manual.set_index('WellID',inplace=True)\n",
    "\n",
    "manual[\"MeasuredLevel\"] = np.nan\n",
    "manual[\"Temp\"] = np.nan\n",
    "manual[\"BaroEfficiencyCorrected\"] = np.nan \n",
    "manual[\"DeltaLevel\"] = np.nan\n",
    "manual[\"DriftCorrection\"] = np.nan\n",
    "manual[\"MeasuredBy\"] = np.nan\n",
    "manual[\"Tape\"] = 1\n",
    "manual[\"DTWBelowGroundSurface\"] = np.nan\n",
    "manual[\"WaterElevation\"] = np.nan\n",
    "#manualrecent[\"DTWBelowGroundSurface\"] = np.nan\n",
    "manlist= [int(i) for i in manual.index.tolist()]\n",
    "\n",
    "print manlist\n",
    "for i in manlist:\n",
    "    try:\n",
    "        manual.loc[i,\"DTWBelowCasing\"] = manual.loc[i,\"MeasuredDTW\"]\n",
    "        manual.loc[i,\"DTWBelowGroundSurface\"] = manual.loc[i,\"MeasuredDTW\"] - wellinfo.loc[i,\"Offset\"]\n",
    "        manual.loc[i,\"WaterElevation\"] = wellinfo.loc[i,'GroundElevation'] - manual.loc[i,\"DTWBelowGroundSurface\"]\n",
    "    except(KeyError):\n",
    "        pass\n",
    "\n",
    "outpath = pathlist[0] + '\\\\' + pathlist[1] + '\\\\' + pathlist[2] + '\\\\' + pathlist[3] + '\\\\' + pathlist[4] + '\\\\' + 'Manual' + '.csv'  \n",
    "manual.to_csv(outpath, index=True, columns= [\"DateTime\",\"MeasuredLevel\",\"Temp\",\"BaroEfficiencyCorrected\",\"DeltaLevel\",\n",
    "                                             \"MeasuredDTW\",\"DriftCorrection\",\"DTWBelowCasing\",\"DTWBelowGroundSurface\",\n",
    "                                             \"WaterElevation\",\"Tape\",\"MeasuredBy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import All Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdf_pages = PdfPages(folder+'wells.pdf')\n",
    "for i in wellinfo.loc[:,'full_file_name']:\n",
    "    print i\n",
    "    g = snake.imp_new_well(folder+'\\\\'+i, wellinfo, manual, barodata)\n",
    "    glist = g.columns.tolist()\n",
    "    for j in range(len(glist)):\n",
    "        if 'pw' in glist[j]:\n",
    "            h = glist[j]\n",
    "    y1 = g['WaterElevation'].values\n",
    "    y2 = g[h].values\n",
    "    x1 = g['DateTime'].values\n",
    "    wellname, wellid = snake.getwellid(folder+'\\\\'+i,wellinfo1)\n",
    "    ylast = wellinfo[wellinfo['WellID']==wellid]['GroundElevation'].values[0] + wellinfo[wellinfo['WellID']==wellid]['Offset'].values[0] - fcl(manual[manual['WellID']== wellid],max(g.index.to_datetime()))[1]\n",
    "    yfirst = wellinfo[wellinfo['WellID']==wellid]['GroundElevation'].values[0] + wellinfo[wellinfo['WellID']==wellid]['Offset'].values[0] - fcl(manual[manual['WellID']== wellid],min(g.index.to_datetime()))[1]\n",
    "    xlast = (fcl(manual[manual['WellID']== wellid],max(g.index.to_datetime()))).name.to_datetime()\n",
    "    xfirst = (fcl(manual[manual['WellID']== wellid],min(g.index.to_datetime()))).name.to_datetime()\n",
    "    x4 = [xfirst,xlast]\n",
    "    y4 = [yfirst,ylast]\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.scatter(x4,y4,color='purple')\n",
    "    ax1.plot(x1,y1,color='blue',label='Water Level Elevation')\n",
    "    ax1.set_ylabel('Water Level Elevation',color='blue')\n",
    "    y_formatter = tick.ScalarFormatter(useOffset=False)\n",
    "    ax1.yaxis.set_major_formatter(y_formatter)\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel('Barometric Pressure (ft)', color='red') \n",
    "    ax2.plot(x1,y2,color='red',label='Barometric pressure (ft)')\n",
    "    h1, l1 = ax1.get_legend_handles_labels()\n",
    "    h2, l2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(h1+h2, l1+l2, loc=3)\n",
    "    \n",
    "    plt.title('Well: ' + wellname.title() + '  ' + 'Total Drift = ' + str(g['DriftCorrection'][-1]))\n",
    "    pdf_pages.savefig(fig)\n",
    "    fig.close()\n",
    "pdf_pages.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "infile = Drive + ':\\\\GWP\\\\Groundwater\\\\Courthouse_Wash_Transducer_Data\\\\chwnav 2015_06_12.xle'\n",
    "with open(infile) as fd:\n",
    "    # parse xml\n",
    "    obj = xmltodict.parse(fd.read(),encoding=\"ISO-8859-1\")\n",
    "# navigate through xml to the data\n",
    "wellrawdata = obj['Body_xle']['Data']['Log']\n",
    "# convert xml data to pandas dataframe\n",
    "f = pd.DataFrame(wellrawdata)\n",
    "# get header names and apply to the pandas dataframe\n",
    "f[str(obj['Body_xle']['Ch2_data_header']['Identification']).title()] = f['ch2']\n",
    "\n",
    "tempunit = (obj['Body_xle']['Ch2_data_header']['Unit'])\n",
    "if tempunit == 'Deg C' or tempunit == u'\\N{DEGREE SIGN}' + u'C':\n",
    "    f[str(obj['Body_xle']['Ch2_data_header']['Identification']).title()] = f['ch2'].convert_objects(convert_numeric=True)\n",
    "elif tempunit == 'Deg F' or tempunit == u'\\N{DEGREE SIGN}' + u'F': \n",
    "    f[str(obj['Body_xle']['Ch2_data_header']['Identification']).title()] = f['ch2'].convert_objects(convert_numeric=True)*0.33456\n",
    "\n",
    "unit = str(obj['Body_xle']['Ch1_data_header']['Unit']).lower()\n",
    "if unit == \"feet\" or unit == \"ft\":\n",
    "    f[str(obj['Body_xle']['Ch1_data_header']['Identification']).title()] = f['ch1'].convert_objects(convert_numeric=True)\n",
    "elif unit == \"kpa\":\n",
    "    f[str(obj['Body_xle']['Ch1_data_header']['Identification']).title()] = f['ch1'].convert_objects(convert_numeric=True)*0.33456\n",
    "elif unit == \"mbar\":\n",
    "    f[str(obj['Body_xle']['Ch1_data_header']['Identification']).title()] = f['ch1'].convert_objects(convert_numeric=True)*0.0334552565551\n",
    "elif unit == \"psi\":\n",
    "    f[str(obj['Body_xle']['Ch1_data_header']['Identification']).title()] = f['ch1'].convert_objects(convert_numeric=True)*2.306726\n",
    "elif unit == \"m\" or unit == \"meters\":\n",
    "    f[str(obj['Body_xle']['Ch1_data_header']['Identification']).title()] = f['ch1'].convert_objects(convert_numeric=True)*3.28084\n",
    "else:\n",
    "    f[str(obj['Body_xle']['Ch1_data_header']['Identification']).title()] = f['ch1'].convert_objects(convert_numeric=True)\n",
    "    print \"Unknown Units\"\n",
    "# add extension-free file name to dataframe\n",
    "f['name'] = snake.getfilename(infile)\n",
    "# combine Date and Time fields into one field\n",
    "f['DateTime'] = pd.to_datetime(f.apply(lambda x: x['Date'] + ' ' + x['Time'], 1))\n",
    "f[str(obj['Body_xle']['Ch1_data_header']['Identification']).title()] = f[str(obj['Body_xle']['Ch1_data_header']['Identification']).title()].convert_objects(convert_numeric=True)\n",
    "f[str(obj['Body_xle']['Ch2_data_header']['Identification']).title()] = f[str(obj['Body_xle']['Ch2_data_header']['Identification']).title()].convert_objects(convert_numeric=True)\n",
    "f = f.reset_index()\n",
    "f = f.set_index('DateTime')\n",
    "f = f.drop(['Date','Time','@id','ch1','ch2','index','ms'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import snake\n",
    "infile = Drive + ':\\\\GWP\\\\Groundwater\\\\Courthouse_Wash_Transducer_Data\\\\chwnav 2015_06_12.xle'\n",
    "b = snake.hourly_resample(barodata, 0)\n",
    "f = snake.new_xle_imp(infile)\n",
    "f = snake.hourly_resample(f, 0)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = snake.new_xle_imp(infile)\n",
    "bse =57\n",
    "f = f.resample('1Min', how='first', closed='left')\n",
    "#f\n",
    "f = f.interpolate(method='time')\n",
    "f = f.resample('60Min', how='first', closed='left', base=bse)\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import One File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputfile = r\"U:\\GWP\\Groundwater\\Courthouse_Wash_Transducer_Data\\chwnav 2015_06_12.xle\"\n",
    "\n",
    "g = snake.imp_new_well(inputfile, wellinfo, manual, barodata)\n",
    "glist = g.columns.tolist()\n",
    "for j in range(len(glist)):\n",
    "        if 'pw' in glist[j]:\n",
    "            h = glist[j]\n",
    "y1 = g['WaterElevation'].values\n",
    "y2 = g[h].values\n",
    "x1 = g['DateTime'].values\n",
    "\n",
    "wellname, wellid = getwellid(inputfile)\n",
    "ylast = wellinfo[wellinfo['WellID']==wellid]['GroundElevation'].values[0] + wellinfo[wellinfo['WellID']==wellid]['Offset'].values[0] - fcl(manual[manual['WellID']== wellid],max(g.index.to_datetime()))[1]\n",
    "yfirst = wellinfo[wellinfo['WellID']==wellid]['GroundElevation'].values[0] + wellinfo[wellinfo['WellID']==wellid]['Offset'].values[0] - fcl(manual[manual['WellID']== wellid],min(g.index.to_datetime()))[1]\n",
    "xlast = (fcl(manual[manual['WellID']== wellid],max(g.index.to_datetime()))).name.to_datetime()\n",
    "xfirst = (fcl(manual[manual['WellID']== wellid],min(g.index.to_datetime()))).name.to_datetime()\n",
    "x4 = [xfirst,xlast]\n",
    "y4 = [yfirst,ylast]\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.scatter(x4,y4,color='purple')\n",
    "ax1.plot(x1,y1,color='red')\n",
    "y_formatter = tick.ScalarFormatter(useOffset=False)\n",
    "ax1.yaxis.set_major_formatter(y_formatter)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(x1,y2,color='blue')\n",
    "plt.title(getfilename(inputfile)+'  '+str(g['DriftCorrection'][-1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q = {}\n",
    "\n",
    "for i in wellinfo.loc[:,'full_file_name']:\n",
    "    wellname, wellid = getwellid(folder+'\\\\'+i)\n",
    "    q[wellname] = imp_new_well(folder+'\\\\'+i, wellinfo, manual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q.names.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alldf = ag13a.append(q)\n",
    "outpath = pathlist[0] + '\\\\' + pathlist[1] + '\\\\' + pathlist[2] + '\\\\' + pathlist[3] + '\\\\' + pathlist[4] + '\\\\' + 'all' + '.csv'\n",
    "alldf.to_csv(outpath, index=False, columns= [\"WellID\",\"DateTime\",\"MeasuredLevel\",\"Temp\",\"BaroEfficiencyCorrected\",\"DeltaLevel\",\n",
    "                                             \"MeasuredDTW\",\"DriftCorrection\",\"DTWBelowCasing\",\"DTWBelowGroundSurface\",\n",
    "                                             \"WaterElevation\",\"Tape\",\"MeasuredBy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dailyavgfiles = r\"U:\\GWP\\Snake Valley Water\\Transducer Data\\Individual Sites\\Daily Averages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "well = r\"U:\\GWP\\Snake Valley Water\\Transducer Data\\Individual Sites\\Daily Averages\\ag13b.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hourly = pd.read_excel(well,'input',parse_dates=True,index_col='DateTime')\n",
    "hwl = hourly[\"WaterElevation\"].resample('D',how='mean')\n",
    "hwl = hwl.interpolate(how='Time')\n",
    "hwl.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
